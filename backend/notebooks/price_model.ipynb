{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d3f2b6",
   "metadata": {
    "papermill": {
     "duration": 0.00279,
     "end_time": "2025-12-05T15:50:40.664812",
     "exception": false,
     "start_time": "2025-12-05T15:50:40.662022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sklearn regularized regression with target scaling\n",
    "\n",
    "Polynomial feature expansion (degrees 1–3) with feature scaling and Ridge regularization, evaluated via 10-fold (~90/10) cross-validation. Target (`y`) is scaled via `TransformedTargetRegressor` so training occurs in standardized space. Logs train/validation metrics per fold, picks the best configuration, and saves the fitted best model plus logs for downstream visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b742ad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T15:50:40.671030Z",
     "iopub.status.busy": "2025-12-05T15:50:40.670558Z",
     "iopub.status.idle": "2025-12-05T15:50:44.774918Z",
     "shell.execute_reply": "2025-12-05T15:50:44.773609Z"
    },
    "papermill": {
     "duration": 4.109702,
     "end_time": "2025-12-05T15:50:44.776896",
     "exception": false,
     "start_time": "2025-12-05T15:50:40.667194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /kaggle\n",
      "Data path: /kaggle/input/price-data/cleaned_combined_price_data.csv\n",
      "Output dir: /kaggle/working/price_model\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_PATH = PROJECT_ROOT / \"input\" / \"price-data\" / \"cleaned_combined_price_data.csv\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"working\" / \"price_model\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be1831b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T15:50:44.782645Z",
     "iopub.status.busy": "2025-12-05T15:50:44.782112Z",
     "iopub.status.idle": "2025-12-05T15:50:47.138690Z",
     "shell.execute_reply": "2025-12-05T15:50:47.137232Z"
    },
    "papermill": {
     "duration": 2.361604,
     "end_time": "2025-12-05T15:50:47.140548",
     "exception": false,
     "start_time": "2025-12-05T15:50:44.778944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after cleaning: 387636 rows, 20 features\n",
      "   ZIPCODE  OWN_OCC  GROSS_TAX  GROSS_AREA  LIVING_AREA  NUM_BLDGS    LUC  \\\n",
      "0   2128.0      1.0    7676.00      3353.0       2202.0        1.0  105.0   \n",
      "1   2128.0      1.0    7947.02      3299.0       2307.0        1.0  105.0   \n",
      "2   2128.0     -1.0    7794.44      3392.0       2268.0        1.0  105.0   \n",
      "3   2128.0     -1.0    7126.49      3108.0       2028.0        1.0  105.0   \n",
      "4   2128.0      1.0    7620.52      3700.0       2546.0        1.0  104.0   \n",
      "\n",
      "   RES_FLOOR  YR_LATEST_DEVELOPED  BED_RMS  FULL_BTH  HLF_BTH  TT_RMS  \\\n",
      "0        3.0               1900.0      6.0       3.0      0.0    12.0   \n",
      "1        3.0               2000.0      3.0       3.0      0.0     9.0   \n",
      "2        3.0               1985.0      5.0       3.0      2.0    13.0   \n",
      "3        3.0               1991.0      5.0       3.0      0.0    11.0   \n",
      "4        3.0               1978.0      6.0       3.0      2.0    13.0   \n",
      "\n",
      "   KITCHEN_TYPE  HEAT_TYPE  AC_TYPE  NUM_PARKING  PROP_VIEW  KITCHENS  \\\n",
      "0           2.0       -2.0     -1.0          3.0        0.0       3.0   \n",
      "1           2.0        1.0      2.0          0.0        0.0       3.0   \n",
      "2           2.0       -1.0     -1.0          0.0        0.0       3.0   \n",
      "3           2.0       -2.0     -1.0          0.0        0.0       3.0   \n",
      "4          -1.0       -2.0     -1.0          0.0        0.0       2.0   \n",
      "\n",
      "   FIREPLACES  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n"
     ]
    }
   ],
   "source": [
    "# Load cleaned data and prepare numeric features/target\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Convert currency-like columns to numeric\n",
    "for col in [\"GROSS_TAX\"]:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[^0-9.-]\", \"\", regex=True)\n",
    "        .replace(\"\", np.nan)\n",
    "    )\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "TARGET_COL = \"TOTAL_VALUE\"\n",
    "feature_cols = [col for col in df.columns if col != TARGET_COL]\n",
    "\n",
    "clean_df = df.dropna(subset=[TARGET_COL, *feature_cols]).reset_index(drop=True)\n",
    "X = clean_df[feature_cols].astype(float)\n",
    "y = clean_df[TARGET_COL].astype(float)\n",
    "\n",
    "print(f\"Dataset after cleaning: {clean_df.shape[0]} rows, {X.shape[1]} features\")\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578af59d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T15:50:47.146809Z",
     "iopub.status.busy": "2025-12-05T15:50:47.146481Z",
     "iopub.status.idle": "2025-12-05T17:27:45.349497Z",
     "shell.execute_reply": "2025-12-05T17:27:45.348543Z"
    },
    "papermill": {
     "duration": 5818.210423,
     "end_time": "2025-12-05T17:27:45.353448",
     "exception": false,
     "start_time": "2025-12-05T15:50:47.143025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 | Fold 1/10 | train MSE: 100639622.89 | val MSE: 77093255.08 | alpha: 10.0\n",
      "Degree 1 | Fold 2/10 | train MSE: 96472255.15 | val MSE: 114562025.96 | alpha: 10.0\n",
      "Degree 1 | Fold 3/10 | train MSE: 100697870.24 | val MSE: 76545533.44 | alpha: 10.0\n",
      "Degree 1 | Fold 4/10 | train MSE: 98798881.79 | val MSE: 93598427.29 | alpha: 10.0\n",
      "Degree 1 | Fold 5/10 | train MSE: 95899086.48 | val MSE: 119762103.99 | alpha: 10.0\n",
      "Degree 1 | Fold 6/10 | train MSE: 98559224.36 | val MSE: 95802128.16 | alpha: 10.0\n",
      "Degree 1 | Fold 7/10 | train MSE: 93772787.76 | val MSE: 139070143.92 | alpha: 10.0\n",
      "Degree 1 | Fold 8/10 | train MSE: 99732906.78 | val MSE: 85322397.97 | alpha: 10.0\n",
      "Degree 1 | Fold 9/10 | train MSE: 100478239.90 | val MSE: 78497175.78 | alpha: 10.0\n",
      "Degree 1 | Fold 10/10 | train MSE: 97655183.22 | val MSE: 103960300.81 | alpha: 1.0\n",
      "Degree 2 | Fold 1/10 | train MSE: 84292036.64 | val MSE: 74652418.46 | alpha: 0.01\n",
      "Degree 2 | Fold 2/10 | train MSE: 82556159.86 | val MSE: 98588160.21 | alpha: 1.0\n",
      "Degree 2 | Fold 3/10 | train MSE: 83992365.71 | val MSE: 78002434.46 | alpha: 0.1\n",
      "Degree 2 | Fold 4/10 | train MSE: 83626164.42 | val MSE: 80611252.86 | alpha: 0.01\n",
      "Degree 2 | Fold 5/10 | train MSE: 81998955.49 | val MSE: 97545996.74 | alpha: 0.01\n",
      "Degree 2 | Fold 6/10 | train MSE: 82658025.71 | val MSE: 92809826.74 | alpha: 0.01\n",
      "Degree 2 | Fold 7/10 | train MSE: 81581056.78 | val MSE: 109466348.24 | alpha: 0.01\n",
      "Degree 2 | Fold 8/10 | train MSE: 84245404.90 | val MSE: 75082110.50 | alpha: 0.01\n",
      "Degree 2 | Fold 9/10 | train MSE: 83603816.07 | val MSE: 87044638.10 | alpha: 0.1\n",
      "Degree 2 | Fold 10/10 | train MSE: 82628665.11 | val MSE: 92410675.91 | alpha: 0.1\n",
      "Degree 3 | Fold 1/10 | train MSE: 73978268.73 | val MSE: 77330997.17 | alpha: 1.0\n",
      "Degree 3 | Fold 2/10 | train MSE: 74579627.25 | val MSE: 2839603506.60 | alpha: 10.0\n",
      "Degree 3 | Fold 3/10 | train MSE: 74038716.46 | val MSE: 79494660.85 | alpha: 1.0\n",
      "Degree 3 | Fold 4/10 | train MSE: 73689058.70 | val MSE: 81831945.36 | alpha: 1.0\n",
      "Degree 3 | Fold 5/10 | train MSE: 72122479.85 | val MSE: 106419106.12 | alpha: 0.1\n",
      "Degree 3 | Fold 6/10 | train MSE: 74611022.45 | val MSE: 140524509.74 | alpha: 10.0\n",
      "Degree 3 | Fold 7/10 | train MSE: 73068556.45 | val MSE: 151854633.08 | alpha: 1.0\n",
      "Degree 3 | Fold 8/10 | train MSE: 76258782.71 | val MSE: 75087489.13 | alpha: 10.0\n",
      "Degree 3 | Fold 9/10 | train MSE: 75649344.30 | val MSE: 339701533.60 | alpha: 10.0\n",
      "Degree 3 | Fold 10/10 | train MSE: 74834453.11 | val MSE: 129380858.13 | alpha: 10.0\n",
      "Summary metrics by degree:\n",
      "   degree  val_mse_mean   val_mse_std  train_mse_mean  train_mse_std  \\\n",
      "0       1  9.842135e+07  1.982692e+07    9.827061e+07   2.198761e+06   \n",
      "1       2  8.862139e+07  1.096929e+07    8.311827e+07   9.104565e+05   \n",
      "2       3  4.021229e+08  8.159180e+08    7.428303e+07   1.136588e+06   \n",
      "\n",
      "   alpha_mean  alpha_mode  \n",
      "0       9.100       10.00  \n",
      "1       0.136        0.01  \n",
      "2       5.410       10.00  \n"
     ]
    }
   ],
   "source": [
    "# Cross-validate degrees 1–3 using PolynomialFeatures + RidgeCV (with feature/target scaling) and log train/validation metrics\n",
    "\n",
    "def make_regressor(degree: int, alphas=(0.01, 0.1, 1.0, 10.0, 100.0)) -> TransformedTargetRegressor:\n",
    "    feature_pipeline = Pipeline(\n",
    "        [\n",
    "            (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"model\", RidgeCV(alphas=alphas, cv=5, fit_intercept=True)),\n",
    "        ]\n",
    "    )\n",
    "    return TransformedTargetRegressor(\n",
    "        regressor=feature_pipeline,\n",
    "        transformer=StandardScaler(),\n",
    "        check_inverse=False,\n",
    "    )\n",
    "\n",
    "def evaluate_degrees(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    degrees=(1, 2, 3),\n",
    "    n_splits: int = 10,\n",
    "    seed: int = 42,\n",
    "    alphas=(0.01, 0.1, 1.0, 10.0, 100.0),\n",
    "):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    summary_rows = []\n",
    "    fold_rows = []\n",
    "\n",
    "    for degree in degrees:\n",
    "        fold_val_mse = []\n",
    "        fold_train_mse = []\n",
    "        fold_alphas = []\n",
    "        regressor = make_regressor(degree, alphas=alphas)\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X), start=1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            regressor.fit(X_train, y_train)\n",
    "            preds_val = regressor.predict(X_val)  # inverse-transformed\n",
    "            preds_train = regressor.predict(X_train)\n",
    "            val_mse = mean_squared_error(y_val, preds_val)\n",
    "            train_mse = mean_squared_error(y_train, preds_train)\n",
    "            alpha = float(regressor.regressor_.named_steps[\"model\"].alpha_)\n",
    "            fold_val_mse.append(val_mse)\n",
    "            fold_train_mse.append(train_mse)\n",
    "            fold_alphas.append(alpha)\n",
    "            fold_rows.append(\n",
    "                {\n",
    "                    \"degree\": degree,\n",
    "                    \"fold\": fold_idx,\n",
    "                    \"train_mse\": float(train_mse),\n",
    "                    \"val_mse\": float(val_mse),\n",
    "                    \"alpha\": alpha,\n",
    "                    \"train_size\": int(len(train_idx)),\n",
    "                    \"val_size\": int(len(val_idx)),\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"Degree {degree} | Fold {fold_idx}/{n_splits} | \"\n",
    "                f\"train MSE: {train_mse:.2f} | val MSE: {val_mse:.2f} | alpha: {alpha}\"\n",
    "            )\n",
    "\n",
    "        summary_rows.append(\n",
    "            {\n",
    "                \"degree\": degree,\n",
    "                \"val_mse_mean\": float(np.mean(fold_val_mse)),\n",
    "                \"val_mse_std\": float(np.std(fold_val_mse)),\n",
    "                \"train_mse_mean\": float(np.mean(fold_train_mse)),\n",
    "                \"train_mse_std\": float(np.std(fold_train_mse)),\n",
    "                \"alpha_mean\": float(np.mean(fold_alphas)),\n",
    "                \"alpha_mode\": float(pd.Series(fold_alphas).mode().iloc[0]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    fold_df = pd.DataFrame(fold_rows)\n",
    "    return summary_df, fold_df\n",
    "\n",
    "summary_df, fold_df = evaluate_degrees(X, y)\n",
    "print(\"Summary metrics by degree:\")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69092ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T17:27:45.362888Z",
     "iopub.status.busy": "2025-12-05T17:27:45.361759Z",
     "iopub.status.idle": "2025-12-05T17:28:19.183389Z",
     "shell.execute_reply": "2025-12-05T17:28:19.182547Z"
    },
    "papermill": {
     "duration": 33.832181,
     "end_time": "2025-12-05T17:28:19.189121",
     "exception": false,
     "start_time": "2025-12-05T17:27:45.356940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best degree (by mean val MSE): 2\n",
      "Best alpha after full-data fit: 0.1\n",
      "Saved artifacts:\n",
      "- Summary CSV:       /kaggle/working/price_model/ridge_poly_cv_summary.csv\n",
      "- Fold CSV:          /kaggle/working/price_model/ridge_poly_cv_folds.csv\n",
      "- Best folds CSV:    /kaggle/working/price_model/ridge_poly_best_folds.csv\n",
      "- Best model pickle: /kaggle/working/price_model/ridge_poly_best_model.pkl\n",
      "- Best model JSON:   /kaggle/working/price_model/ridge_poly_best_model.json\n"
     ]
    }
   ],
   "source": [
    "# Select best model (lowest mean validation MSE), refit on full data, and persist artifacts\n",
    "\n",
    "# Save aggregate logs\n",
    "summary_path = OUTPUT_DIR / \"ridge_poly_cv_summary.csv\"\n",
    "fold_path = OUTPUT_DIR / \"ridge_poly_cv_folds.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "fold_df.to_csv(fold_path, index=False)\n",
    "\n",
    "# Identify best degree by lowest val_mse_mean\n",
    "best_idx = summary_df[\"val_mse_mean\"].idxmin()\n",
    "best_row = summary_df.loc[best_idx]\n",
    "best_degree = int(best_row[\"degree\"])\n",
    "print(f\"Best degree (by mean val MSE): {best_degree}\")\n",
    "\n",
    "# Refit best regressor on all data\n",
    "alphas_grid = (0.01, 0.1, 1.0, 10.0, 100.0)\n",
    "best_regressor = make_regressor(best_degree, alphas=alphas_grid)\n",
    "best_regressor.fit(X, y)\n",
    "best_alpha = float(best_regressor.regressor_.named_steps[\"model\"].alpha_)\n",
    "print(f\"Best alpha after full-data fit: {best_alpha}\")\n",
    "\n",
    "# Persist best model\n",
    "best_model_path = OUTPUT_DIR / \"ridge_poly_best_model.pkl\"\n",
    "with best_model_path.open(\"wb\") as f:\n",
    "    pickle.dump(best_regressor, f)\n",
    "\n",
    "# Persist best-only fold metrics\n",
    "best_fold_df = fold_df[fold_df[\"degree\"] == best_degree].reset_index(drop=True)\n",
    "best_fold_path = OUTPUT_DIR / \"ridge_poly_best_folds.csv\"\n",
    "best_fold_df.to_csv(best_fold_path, index=False)\n",
    "\n",
    "# Persist JSON summary\n",
    "best_json_path = OUTPUT_DIR / \"ridge_poly_best_model.json\"\n",
    "best_payload = {\n",
    "    \"degrees_tested\": sorted(summary_df[\"degree\"].tolist()),\n",
    "    \"alphas_grid\": list(alphas_grid),\n",
    "    \"outer_cv_folds\": 10,\n",
    "    \"inner_cv_folds\": 5,\n",
    "    \"dataset_rows\": int(X.shape[0]),\n",
    "    \"dataset_features\": int(X.shape[1]),\n",
    "    \"best\": {\n",
    "        \"degree\": best_degree,\n",
    "        \"alpha\": best_alpha,\n",
    "        \"val_mse_mean\": float(best_row[\"val_mse_mean\"]),\n",
    "        \"val_mse_std\": float(best_row[\"val_mse_std\"]),\n",
    "        \"train_mse_mean\": float(best_row[\"train_mse_mean\"]),\n",
    "        \"train_mse_std\": float(best_row[\"train_mse_std\"]),\n",
    "    },\n",
    "    \"summary\": summary_df.to_dict(orient=\"records\"),\n",
    "    \"folds_best\": best_fold_df.to_dict(orient=\"records\"),\n",
    "}\n",
    "pd.Series(best_payload).to_json(best_json_path, indent=2)\n",
    "\n",
    "print(\"Saved artifacts:\")\n",
    "print(f\"- Summary CSV:       {summary_path}\")\n",
    "print(f\"- Fold CSV:          {fold_path}\")\n",
    "print(f\"- Best folds CSV:    {best_fold_path}\")\n",
    "print(f\"- Best model pickle: {best_model_path}\")\n",
    "print(f\"- Best model JSON:   {best_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2b4dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T17:28:19.203436Z",
     "iopub.status.busy": "2025-12-05T17:28:19.202656Z",
     "iopub.status.idle": "2025-12-05T17:28:27.344978Z",
     "shell.execute_reply": "2025-12-05T17:28:27.343705Z"
    },
    "papermill": {
     "duration": 8.15162,
     "end_time": "2025-12-05T17:28:27.346541",
     "exception": false,
     "start_time": "2025-12-05T17:28:19.194921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to: /kaggle/working/price_model/ridge_poly_predictions.csv\n",
      "   TOTAL_VALUE  PRED_TOTAL_VALUE  PCT_DIFF\n",
      "0     719400.0     713110.440757 -0.874278\n",
      "1     744800.0     737586.239413 -0.968550\n",
      "2     730500.0     726837.574258 -0.501359\n",
      "3     667900.0     662024.647242 -0.879676\n",
      "4     714200.0     709944.438946 -0.595850\n"
     ]
    }
   ],
   "source": [
    "# Build full prediction DataFrame with actuals, predictions, and percentage error\n",
    "\n",
    "# Use the best_regressor already fit on full data above\n",
    "preds_all = best_regressor.predict(X)\n",
    "results_df = clean_df.copy()\n",
    "results_df[\"PRED_TOTAL_VALUE\"] = preds_all\n",
    "results_df[\"PCT_DIFF\"] = ((results_df[\"PRED_TOTAL_VALUE\"] - results_df[\"TOTAL_VALUE\"]) / results_df[\"TOTAL_VALUE\"]) * 100\n",
    "\n",
    "preds_path = OUTPUT_DIR / \"ridge_poly_predictions.csv\"\n",
    "results_df.to_csv(preds_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to: {preds_path}\")\n",
    "print(results_df[[\"TOTAL_VALUE\", \"PRED_TOTAL_VALUE\", \"PCT_DIFF\"]].head())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8912606,
     "sourceId": 13982539,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5872.652152,
   "end_time": "2025-12-05T17:28:28.071954",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-05T15:50:35.419802",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
