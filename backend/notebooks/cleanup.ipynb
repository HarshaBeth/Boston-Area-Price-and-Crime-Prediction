{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0fc7c1",
   "metadata": {},
   "source": [
    "# Boston Property and Crime Cleanup\n",
    "This notebook rebuilds the preprocessing pipeline for Boston property assessment data (2020-2025) and Boston Police Department incident data. It standardizes schemas, engineers features, and exports cleaned tables for downstream modeling and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bfc68b",
   "metadata": {},
   "source": [
    "## Goals\n",
    "- consolidate yearly property assessment extracts into a normalized schema\n",
    "- engineer housing value features with light imputation and winsorization\n",
    "- clean Boston incident records for spatial and temporal aggregation\n",
    "- export tidy csv/parquet outputs under `processed/` for future notebooks and apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdde1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks\n",
      "Project root: /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction\n",
      "Processed output dir: /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed\n",
      "Property source files:\n",
      " - data2020-full.csv FOUND\n",
      " - data2021-full.csv FOUND\n",
      " - fy2022pa-4.csv FOUND\n",
      " - fy2023-property-assessment-data.csv FOUND\n",
      " - fy2024-property-assessment-data_1_5_2024.csv FOUND\n",
      " - fy2025-property-assessment-data_12_30_2024.csv FOUND\n",
      "Crime file: CrimeData.csv FOUND\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 60)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "NB_DIR = Path.cwd().resolve()\n",
    "ROOT = NB_DIR.parents[1]\n",
    "RAW_PROPERTY_FILES = [\n",
    "    ROOT / \"backend\"/ \"data\" / \"data2020-full.csv\",\n",
    "    ROOT / \"backend\"/ \"data\" / \"data2021-full.csv\",\n",
    "    ROOT / \"backend\"/ \"data\" / \"fy2022pa-4.csv\",\n",
    "    ROOT / \"backend\"/ \"data\" / \"fy2023-property-assessment-data.csv\",\n",
    "    ROOT / \"backend\"/ \"data\" / \"fy2024-property-assessment-data_1_5_2024.csv\",\n",
    "    ROOT / \"backend\"/ \"data\" / \"fy2025-property-assessment-data_12_30_2024.csv\",\n",
    "]\n",
    "CRIME_FILE = ROOT / \"backend\"/ \"data\" / \"CrimeData.csv\"\n",
    "OUT_DIR = NB_DIR / \"processed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Notebook directory:\", NB_DIR)\n",
    "print(\"Project root:\", ROOT)\n",
    "print(\"Processed output dir:\", OUT_DIR)\n",
    "print(\"Property source files:\")\n",
    "for path in RAW_PROPERTY_FILES:\n",
    "    print(\" -\", path.name, \"FOUND\" if path.exists() else \"MISSING\")\n",
    "print(\"Crime file:\", CRIME_FILE.name, \"FOUND\" if CRIME_FILE.exists() else \"MISSING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a15cfb",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "Helper functions shared across the property and crime pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b3a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "def safe_read_csv(path: Path, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Read a csv defensively, returning an empty frame if the file is missing or malformed.\"\"\"\n",
    "    if not path.exists():\n",
    "        print(f\"WARN: missing file {path}\")\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        return pd.read_csv(path, low_memory=False, encoding_errors=\"ignore\", **kwargs)\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        print(f\"ERROR reading {path.name}: {exc}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def detect_year_from_filename(path: Path) -> float:\n",
    "    match = re.search(r\"(20\\d{2})\", path.name)\n",
    "    return int(match.group(1)) if match else np.nan\n",
    "\n",
    "\n",
    "def to_numeric_clean(series: pd.Series) -> pd.Series:\n",
    "    if series is None or series.empty:\n",
    "        return pd.Series(dtype=\"float64\")\n",
    "    cleaned = series.astype(str).str.replace(r\"[^0-9\\.-]\", \"\", regex=True)\n",
    "    return pd.to_numeric(cleaned, errors=\"coerce\")\n",
    "\n",
    "\n",
    "FIELD_PATTERNS: Dict[str, List[str]] = {\n",
    "    \"parcel_id\": [r\"\\bPID\\b\", r\"PARCEL\", r\"GIS_ID\"],\n",
    "    \"street_num\": [r\"ST[_ ]?NUM\", r\"STREET_NUM\"],\n",
    "    \"street_name\": [r\"ST[_ ]?NAME(?!_SUF)\", r\"STREET_?NAME\"],\n",
    "    \"street_suffix\": [r\"ST[_ ]?NAME[_ ]?SUF\", r\"STREET[_ ]?SUF\"],\n",
    "    \"unit\": [r\"\\bUNIT\\b\"],\n",
    "    \"city\": [r\"\\bCITY\\b\"],\n",
    "    \"zip\": [r\"ZIP.?CODE\", r\"\\bZIP\\b\"],\n",
    "    \"res_type\": [r\"RES[_ ]?TYPE\", r\"\\bRES\\b\", r\"\\bLU\\b\", r\"PTYPE\", r\"LUC\", r\"USE\"],\n",
    "    \"building_style\": [r\"STYLE\", r\"BLDG[_ ]?STYLE\", r\"LU_DESC\"],\n",
    "    \"land_sf\": [r\"LAND[_ ]?SF\", r\"LOT[_ ]?SIZE\", r\"LAND AREA\"],\n",
    "    \"living_area\": [r\"LIVING[_ ]?AREA\", r\"GROSS[_ ]?AREA\", r\"TOTAL[_ ]?LIVING\"],\n",
    "    \"year_built\": [r\"YR[_ ]?BUILT\", r\"YEAR[_ ]?BUILT\"],\n",
    "    \"total_value\": [r\"TOTAL[_ ]?VALUE\", r\"AV[_ ]?TOTAL\", r\"ASSESS.*TOTAL\"],\n",
    "    \"latitude\": [r\"\\bLAT(ITUDE)?\\b\"],\n",
    "    \"longitude\": [r\"\\bLON(GITUDE)?\\b\"],\n",
    "}\n",
    "\n",
    "\n",
    "def find_column(columns: List[str], patterns: List[str]) -> str | None:\n",
    "    for pattern in patterns:\n",
    "        for col in columns:\n",
    "            if re.search(pattern, col, flags=re.IGNORECASE):\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_string_series(series: pd.Series | None) -> pd.Series:\n",
    "    if series is None:\n",
    "        return pd.Series(dtype=\"object\")\n",
    "\n",
    "    cleaned = series.astype(\"object\")\n",
    "    if cleaned.empty:\n",
    "        return pd.Series([None] * len(cleaned), index=cleaned.index, dtype=\"object\")\n",
    "\n",
    "    cleaned = cleaned.where(~pd.isna(cleaned), None)\n",
    "\n",
    "    def _strip(value):\n",
    "        if value is None:\n",
    "            return None\n",
    "        if isinstance(value, str):\n",
    "            return value.strip()\n",
    "        return str(value).strip()\n",
    "\n",
    "    cleaned = cleaned.apply(_strip)\n",
    "    cleaned = cleaned.replace({\"\": None, \"nan\": None, \"NaN\": None, \"NONE\": None, \"None\": None})\n",
    "    return cleaned.astype(\"object\")\n",
    "\n",
    "\n",
    "def compose_address(street_num, street_name, unit, city, zip_code) -> str:\n",
    "    parts = []\n",
    "    if street_num and str(street_num).strip().lower() not in {\"nan\", \"none\"}:\n",
    "        parts.append(str(street_num).strip())\n",
    "    if street_name and str(street_name).strip().lower() not in {\"nan\", \"none\"}:\n",
    "        parts.append(str(street_name).strip())\n",
    "    base = \" \".join(parts).strip()\n",
    "    if unit and str(unit).strip().lower() not in {\"nan\", \"none\"}:\n",
    "        base = f\"{base}, Unit {str(unit).strip()}\" if base else f\"Unit {str(unit).strip()}\"\n",
    "    if city and str(city).strip().lower() not in {\"nan\", \"none\"}:\n",
    "        formatted_city = str(city).strip().title()\n",
    "        base = f\"{base}, {formatted_city}\" if base else formatted_city\n",
    "    if zip_code and str(zip_code).strip().isdigit():\n",
    "        base = f\"{base}, {str(zip_code).strip()}\" if base else str(zip_code).strip()\n",
    "    return base.strip().strip(\",\")\n",
    "\n",
    "\n",
    "def winsorize_grouped(df: pd.DataFrame, col: str, group: str, lower: float = 0.01, upper: float = 0.99) -> pd.DataFrame:\n",
    "    if col not in df.columns or group not in df.columns:\n",
    "        return df\n",
    "\n",
    "    def _clip(s: pd.Series) -> pd.Series:\n",
    "        if s.dropna().empty:\n",
    "            return s\n",
    "        lower_q = s.quantile(lower)\n",
    "        upper_q = s.quantile(upper)\n",
    "        return s.clip(lower_q, upper_q)\n",
    "\n",
    "    df[col] = df.groupby(group)[col].transform(_clip)\n",
    "    return df\n",
    "\n",
    "\n",
    "def hierarchical_impute(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        if {\"zip\", \"res_type\"}.issubset(df.columns):\n",
    "            df[col] = df[col].fillna(df.groupby([\"zip\", \"res_type\"])[col].transform(\"median\"))\n",
    "        if \"zip\" in df.columns:\n",
    "            df[col] = df[col].fillna(df.groupby(\"zip\")[col].transform(\"median\"))\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "\n",
    "def safe_to_parquet(df: pd.DataFrame, path: Path) -> bool:\n",
    "    \"\"\"Write parquet if engine available; return True when successful.\"\"\"\n",
    "    try:\n",
    "        df.to_parquet(path, index=False)\n",
    "        return True\n",
    "    except ImportError as err:\n",
    "        print(f\"WARN: {err}. Skipping parquet write for {path.name}.\")\n",
    "    except ValueError as err:\n",
    "        print(f\"WARN: Failed to write {path.name}: {err}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def top_mode(series: pd.Series):\n",
    "    counts = series.dropna().value_counts()\n",
    "    return counts.index[0] if not counts.empty else np.nan\n",
    "\n",
    "\n",
    "def make_daypart(hour) -> str | float:\n",
    "    if pd.isna(hour):\n",
    "        return np.nan\n",
    "    try:\n",
    "        hour_int = int(hour)\n",
    "    except (TypeError, ValueError):  # noqa: PERF203\n",
    "        return np.nan\n",
    "    if 5 <= hour_int < 12:\n",
    "        return \"morning\"\n",
    "    if 12 <= hour_int < 17:\n",
    "        return \"afternoon\"\n",
    "    if 17 <= hour_int < 21:\n",
    "        return \"evening\"\n",
    "    return \"overnight\"\n",
    "\n",
    "\n",
    "BOSTON_BOUNDS = {\"lat_min\": 42.0, \"lat_max\": 42.6, \"lon_min\": -71.2, \"lon_max\": -70.9}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925c5850",
   "metadata": {},
   "source": [
    "## Property pipeline\n",
    "Standardize yearly assessment files, engineer housing metrics, and export clean tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5279da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROPERTY_CPI_FACTORS = {2020: 1.20, 2021: 1.12, 2022: 1.08, 2023: 1.04, 2024: 1.02, 2025: 1.00}\n",
    "CURRENT_YEAR = 2025\n",
    "\n",
    "\n",
    "def canonicalize_property_file(path: Path) -> Tuple[pd.DataFrame, Dict[str, str]]:\n",
    "    raw = safe_read_csv(path)\n",
    "    diagnostics: Dict[str, str] = {\"source\": path.name, \"rows\": len(raw)}\n",
    "    if raw.empty:\n",
    "        diagnostics[\"missing_columns\"] = list(FIELD_PATTERNS.keys())\n",
    "        return pd.DataFrame(), diagnostics\n",
    "\n",
    "    columns = list(raw.columns)\n",
    "    mapping = {field: find_column(columns, patterns) for field, patterns in FIELD_PATTERNS.items()}\n",
    "    diagnostics[\"mapping\"] = mapping\n",
    "    diagnostics[\"missing_columns\"] = [field for field, col in mapping.items() if col is None]\n",
    "\n",
    "    out = pd.DataFrame(index=raw.index)\n",
    "    out[\"source_file\"] = path.name\n",
    "    out[\"source_year\"] = detect_year_from_filename(path)\n",
    "\n",
    "    def take(field: str) -> pd.Series:\n",
    "        col = mapping.get(field)\n",
    "        if col is None or col not in raw.columns:\n",
    "            return pd.Series(np.nan, index=raw.index)\n",
    "        return raw[col]\n",
    "\n",
    "    street_num = clean_string_series(take(\"street_num\")).str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "    street_name = clean_string_series(take(\"street_name\"))\n",
    "    suffix_col = mapping.get(\"street_suffix\")\n",
    "    if suffix_col:\n",
    "        suffix = clean_string_series(raw[suffix_col])\n",
    "        street_name = (street_name.fillna(\"\") + \" \" + suffix.fillna(\"\")).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "        street_name = street_name.replace({\"\": np.nan})\n",
    "    unit = clean_string_series(take(\"unit\"))\n",
    "    city = clean_string_series(take(\"city\")).str.title()\n",
    "    zip_code = take(\"zip\").astype(str).str.extract(r\"(\\d{5})\", expand=False)\n",
    "\n",
    "    out[\"parcel_id\"] = clean_string_series(take(\"parcel_id\")).str.replace(r\"\\.0$\", \"\", regex=True).str.upper()\n",
    "    out[\"street_num\"] = street_num\n",
    "    out[\"street_name\"] = street_name\n",
    "    out[\"unit\"] = unit\n",
    "    out[\"city\"] = city\n",
    "    out[\"zip\"] = zip_code\n",
    "    out[\"res_type\"] = clean_string_series(take(\"res_type\"))\n",
    "    out[\"building_style\"] = clean_string_series(take(\"building_style\"))\n",
    "    out[\"land_sf\"] = to_numeric_clean(take(\"land_sf\"))\n",
    "    out[\"living_area\"] = to_numeric_clean(take(\"living_area\"))\n",
    "    out[\"year_built\"] = to_numeric_clean(take(\"year_built\"))\n",
    "    out[\"total_value\"] = to_numeric_clean(take(\"total_value\"))\n",
    "    out[\"latitude\"] = pd.to_numeric(take(\"latitude\"), errors=\"coerce\")\n",
    "    out[\"longitude\"] = pd.to_numeric(take(\"longitude\"), errors=\"coerce\")\n",
    "    out[\"year\"] = out[\"source_year\"]\n",
    "    out[\"addr_std\"] = [\n",
    "        compose_address(sn, st, un, ct, zp)\n",
    "        for sn, st, un, ct, zp in zip(street_num, street_name, unit, city, zip_code)\n",
    "    ]\n",
    "    out[\"addr_std\"] = pd.Series(out[\"addr_std\"], index=out.index).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    out.loc[out[\"addr_std\"].isin([\"\", \"nan\", \"None\", \"NONE\"]), \"addr_std\"] = np.nan\n",
    "\n",
    "    return out, diagnostics\n",
    "\n",
    "\n",
    "PROPERTY_KEEP_COLS = [\n",
    "    \"parcel_id\",\n",
    "    \"addr_std\",\n",
    "    \"street_num\",\n",
    "    \"street_name\",\n",
    "    \"unit\",\n",
    "    \"city\",\n",
    "    \"zip\",\n",
    "    \"res_type\",\n",
    "    \"building_style\",\n",
    "    \"land_sf\",\n",
    "    \"living_area\",\n",
    "    \"year_built\",\n",
    "    \"total_value\",\n",
    "    \"total_value_real_2025\",\n",
    "    \"price_per_sqft\",\n",
    "    \"lot_coverage\",\n",
    "    \"property_age\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"year\",\n",
    "    \"source_file\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0aa667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2020-full.csv: (175052, 18) | missing: unit, city, latitude, longitude\n",
      "data2021-full.csv: (177091, 18) | missing: street_suffix, unit, latitude, longitude\n",
      "fy2022pa-4.csv: (178598, 18) | missing: street_suffix, unit, latitude, longitude\n",
      "fy2023-property-assessment-data.csv: (180627, 18) | missing: street_suffix, unit, latitude, longitude\n",
      "fy2024-property-assessment-data_1_5_2024.csv: (182242, 18) | missing: street_suffix, unit, latitude, longitude\n",
      "fy2025-property-assessment-data_12_30_2024.csv: (183445, 18) | missing: street_suffix, unit, latitude, longitude\n",
      "Combined property rows: 1077055\n",
      "property_clean shape: (872908, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "property_frames: List[pd.DataFrame] = []\n",
    "property_diagnostics: List[Dict] = []\n",
    "\n",
    "for path in RAW_PROPERTY_FILES:\n",
    "    frame, diag = canonicalize_property_file(path)\n",
    "    property_diagnostics.append(diag)\n",
    "    if frame.empty:\n",
    "        print(f\"{path.name}: skipped (empty)\")\n",
    "        continue\n",
    "    missing = diag.get(\"missing_columns\", [])\n",
    "    missing_msg = \"\" if not missing else f\" | missing: {', '.join(missing)}\"\n",
    "    print(f\"{path.name}: {frame.shape}{missing_msg}\")\n",
    "    property_frames.append(frame)\n",
    "\n",
    "if property_frames:\n",
    "    property_all = pd.concat(property_frames, ignore_index=True)\n",
    "else:\n",
    "    property_all = pd.DataFrame()\n",
    "\n",
    "print(\"Combined property rows:\", len(property_all))\n",
    "\n",
    "if not property_all.empty:\n",
    "    property_all[\"parcel_id\"] = property_all[\"parcel_id\"].str.replace(r\"[^A-Z0-9]\", \"\", regex=True)\n",
    "    property_all[\"parcel_id\"] = property_all[\"parcel_id\"].replace({\"\": np.nan})\n",
    "    property_all = property_all.dropna(subset=[\"parcel_id\"]).copy()\n",
    "\n",
    "    property_all[\"zip\"] = property_all[\"zip\"].where(property_all[\"zip\"].str.fullmatch(r\"\\d{5}\", na=False), np.nan)\n",
    "    property_all[\"addr_std\"] = property_all[\"addr_std\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "    property_all[\"year\"] = property_all[\"year\"].fillna(property_all[\"source_year\"])\n",
    "    property_all[\"year\"] = pd.to_numeric(property_all[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    property_all = hierarchical_impute(property_all, [\"living_area\", \"land_sf\", \"year_built\"])\n",
    "\n",
    "    property_all[\"price_per_sqft\"] = property_all[\"total_value\"] / property_all[\"living_area\"].replace({0: np.nan})\n",
    "    property_all.loc[~np.isfinite(property_all[\"price_per_sqft\"]), \"price_per_sqft\"] = np.nan\n",
    "\n",
    "    property_all[\"lot_coverage\"] = property_all[\"living_area\"] / property_all[\"land_sf\"].replace({0: np.nan})\n",
    "    property_all.loc[~np.isfinite(property_all[\"lot_coverage\"]), \"lot_coverage\"] = np.nan\n",
    "\n",
    "    property_all[\"total_value_real_2025\"] = property_all[\"total_value\"] * property_all[\"year\"].map(PROPERTY_CPI_FACTORS).fillna(1.0)\n",
    "    property_all[\"property_age\"] = CURRENT_YEAR - property_all[\"year_built\"]\n",
    "\n",
    "    for col in [\"price_per_sqft\", \"total_value_real_2025\"]:\n",
    "        property_all = winsorize_grouped(property_all, col, \"year\")\n",
    "\n",
    "    property_all = property_all[\n",
    "        (property_all[\"living_area\"].between(150, 10000) | property_all[\"living_area\"].isna())\n",
    "    ]\n",
    "    property_all = property_all[\n",
    "        (property_all[\"land_sf\"].between(300, 200000) | property_all[\"land_sf\"].isna())\n",
    "    ]\n",
    "    property_all = property_all[\n",
    "        (property_all[\"total_value\"].between(10000, 10000000) | property_all[\"total_value\"].isna())\n",
    "    ]\n",
    "\n",
    "    inside_bounds = (\n",
    "        property_all[\"latitude\"].between(BOSTON_BOUNDS[\"lat_min\"], BOSTON_BOUNDS[\"lat_max\"], inclusive=\"both\")\n",
    "        & property_all[\"longitude\"].between(BOSTON_BOUNDS[\"lon_min\"], BOSTON_BOUNDS[\"lon_max\"], inclusive=\"both\")\n",
    "    )\n",
    "    coord_missing = property_all[\"latitude\"].isna() & property_all[\"longitude\"].isna()\n",
    "    property_all = property_all[inside_bounds | coord_missing]\n",
    "\n",
    "    property_clean = property_all[PROPERTY_KEEP_COLS].copy()\n",
    "else:\n",
    "    property_clean = property_all.copy()\n",
    "\n",
    "print(\"property_clean shape:\", property_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2274e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved property outputs:\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/property_assessments_clean.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/property_assessments_clean.parquet\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/property_by_zip_year.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/property_by_res_type_year.csv\n"
     ]
    }
   ],
   "source": [
    "property_outputs = []\n",
    "if not property_clean.empty:\n",
    "    property_clean_path_csv = OUT_DIR / \"property_assessments_clean.csv\"\n",
    "    property_clean_path_parquet = OUT_DIR / \"property_assessments_clean.parquet\"\n",
    "    property_clean.to_csv(property_clean_path_csv, index=False)\n",
    "    property_outputs.append(property_clean_path_csv)\n",
    "    if safe_to_parquet(property_clean, property_clean_path_parquet):\n",
    "        property_outputs.append(property_clean_path_parquet)\n",
    "\n",
    "    property_by_zip_year = (\n",
    "        property_clean.dropna(subset=[\"zip\", \"year\"])\n",
    "        .groupby([\"zip\", \"year\"], as_index=False)\n",
    "        .agg(\n",
    "            parcel_count=(\"parcel_id\", \"nunique\"),\n",
    "            median_total_value=(\"total_value\", \"median\"),\n",
    "            median_total_value_real_2025=(\"total_value_real_2025\", \"median\"),\n",
    "            median_price_per_sqft=(\"price_per_sqft\", \"median\"),\n",
    "            median_living_area=(\"living_area\", \"median\"),\n",
    "        )\n",
    "        .sort_values([\"year\", \"zip\"])\n",
    "    )\n",
    "    property_by_zip_year_path = OUT_DIR / \"property_by_zip_year.csv\"\n",
    "    property_by_zip_year.to_csv(property_by_zip_year_path, index=False)\n",
    "    property_outputs.append(property_by_zip_year_path)\n",
    "\n",
    "    property_by_res_type_year = (\n",
    "        property_clean.dropna(subset=[\"res_type\", \"year\"])\n",
    "        .groupby([\"res_type\", \"year\"], as_index=False)\n",
    "        .agg(\n",
    "            parcel_count=(\"parcel_id\", \"nunique\"),\n",
    "            median_total_value=(\"total_value\", \"median\"),\n",
    "            median_price_per_sqft=(\"price_per_sqft\", \"median\"),\n",
    "            median_living_area=(\"living_area\", \"median\"),\n",
    "        )\n",
    "        .sort_values([\"res_type\", \"year\"])\n",
    "    )\n",
    "    property_by_res_type_year_path = OUT_DIR / \"property_by_res_type_year.csv\"\n",
    "    property_by_res_type_year.to_csv(property_by_res_type_year_path, index=False)\n",
    "    property_outputs.append(property_by_res_type_year_path)\n",
    "\n",
    "    print(\"Saved property outputs:\")\n",
    "    for path in property_outputs:\n",
    "        print(\" -\", path)\n",
    "else:\n",
    "    print(\"No property rows available; skipped property exports.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80f281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample property rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcel_id</th>\n",
       "      <th>addr_std</th>\n",
       "      <th>zip</th>\n",
       "      <th>total_value</th>\n",
       "      <th>price_per_sqft</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1016122</th>\n",
       "      <td>1702956000</td>\n",
       "      <td>116 MILTON AV, Dorchester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702000.0</td>\n",
       "      <td>317.073171</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052242</th>\n",
       "      <td>2006953002</td>\n",
       "      <td>52 WESTOVER ST, West Roxbury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486000.0</td>\n",
       "      <td>392.251816</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203348</th>\n",
       "      <td>304850788</td>\n",
       "      <td>151 TREMONT ST, Boston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1097100.0</td>\n",
       "      <td>979.553571</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514889</th>\n",
       "      <td>2100772020</td>\n",
       "      <td>1161 COMMONWEALTH AV, Allston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>519.230769</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418382</th>\n",
       "      <td>604081000</td>\n",
       "      <td>160 M ST, South Boston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>759900.0</td>\n",
       "      <td>538.936170</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          parcel_id                       addr_std  zip  total_value  price_per_sqft  year\n",
       "1016122  1702956000      116 MILTON AV, Dorchester  NaN     702000.0      317.073171  2025\n",
       "1052242  2006953002   52 WESTOVER ST, West Roxbury  NaN     486000.0      392.251816  2025\n",
       "203348    304850788         151 TREMONT ST, Boston  NaN    1097100.0      979.553571  2021\n",
       "514889   2100772020  1161 COMMONWEALTH AV, Allston  NaN     337500.0      519.230769  2022\n",
       "418382    604081000         160 M ST, South Boston  NaN     759900.0      538.936170  2022"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median property metrics by year:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_total_value</th>\n",
       "      <th>median_value_real_2025</th>\n",
       "      <th>median_price_per_sqft</th>\n",
       "      <th>median_living_area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>572600.0</td>\n",
       "      <td>687120.0</td>\n",
       "      <td>263.174857</td>\n",
       "      <td>2243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>588700.0</td>\n",
       "      <td>659344.0</td>\n",
       "      <td>393.061532</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>609800.0</td>\n",
       "      <td>658584.0</td>\n",
       "      <td>409.444444</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>632600.0</td>\n",
       "      <td>657904.0</td>\n",
       "      <td>427.455357</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>657650.0</td>\n",
       "      <td>670803.0</td>\n",
       "      <td>444.526642</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>686200.0</td>\n",
       "      <td>686200.0</td>\n",
       "      <td>465.198413</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      median_total_value  median_value_real_2025  median_price_per_sqft  median_living_area\n",
       "year                                                                                       \n",
       "2020            572600.0                687120.0             263.174857              2243.0\n",
       "2021            588700.0                659344.0             393.061532              1440.0\n",
       "2022            609800.0                658584.0             409.444444              1440.0\n",
       "2023            632600.0                657904.0             427.455357              1440.0\n",
       "2024            657650.0                670803.0             444.526642              1440.0\n",
       "2025            686200.0                686200.0             465.198413              1440.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if not property_clean.empty:\n",
    "    display_cols = [\"parcel_id\", \"addr_std\", \"zip\", \"total_value\", \"price_per_sqft\", \"year\"]\n",
    "    sample_preview = property_clean[display_cols].sample(n=min(5, len(property_clean)), random_state=42)\n",
    "    print(\"Sample property rows:\")\n",
    "    display(sample_preview)\n",
    "\n",
    "    print(\"Median property metrics by year:\")\n",
    "    medians_by_year = property_clean.groupby(\"year\")[\n",
    "        [\"total_value\", \"total_value_real_2025\", \"price_per_sqft\", \"living_area\"]\n",
    "    ].median().rename(columns={\n",
    "        \"total_value\": \"median_total_value\",\n",
    "        \"total_value_real_2025\": \"median_value_real_2025\",\n",
    "        \"price_per_sqft\": \"median_price_per_sqft\",\n",
    "        \"living_area\": \"median_living_area\",\n",
    "    })\n",
    "    display(medians_by_year)\n",
    "else:\n",
    "    print(\"Property dataset is empty; nothing to profile.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927677c9",
   "metadata": {},
   "source": [
    "## Crime pipeline\n",
    "Clean Boston incident records, engineer convenience features, and export aggregated views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d14c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CRIME_COLUMN_RENAMES = {\n",
    "    \"INCIDENT_NUMBER\": \"incident_number\",\n",
    "    \"OFFENSE_CODE\": \"offense_code\",\n",
    "    \"OFFENSE_CODE_GROUP\": \"offense_code_group\",\n",
    "    \"OFFENSE_DESCRIPTION\": \"offense_description\",\n",
    "    \"DISTRICT\": \"district\",\n",
    "    \"REPORTING_AREA\": \"reporting_area\",\n",
    "    \"SHOOTING\": \"shooting\",\n",
    "    \"OCCURRED_ON_DATE\": \"occurred_on_date\",\n",
    "    \"YEAR\": \"reported_year\",\n",
    "    \"MONTH\": \"reported_month\",\n",
    "    \"DAY_OF_WEEK\": \"day_of_week\",\n",
    "    \"HOUR\": \"hour\",\n",
    "    \"UCR_PART\": \"ucr_part\",\n",
    "    \"STREET\": \"street\",\n",
    "    \"Lat\": \"latitude\",\n",
    "    \"Long\": \"longitude\",\n",
    "}\n",
    "\n",
    "\n",
    "def clean_crime_data(path: Path) -> Tuple[pd.DataFrame, Dict]:\n",
    "    raw = safe_read_csv(path)\n",
    "    diagnostics = {\"source\": path.name, \"rows\": len(raw)}\n",
    "    if raw.empty:\n",
    "        return pd.DataFrame(), diagnostics\n",
    "\n",
    "    df = raw.rename(columns={col: CRIME_COLUMN_RENAMES.get(col, col.lower()) for col in raw.columns})\n",
    "\n",
    "    df[\"occurred_on_dt\"] = pd.to_datetime(df.get(\"occurred_on_date\"), errors=\"coerce\")\n",
    "    df[\"year\"] = df[\"occurred_on_dt\"].dt.year\n",
    "    df[\"month\"] = df[\"occurred_on_dt\"].dt.month\n",
    "    df[\"hour\"] = pd.to_numeric(df.get(\"hour\"), errors=\"coerce\")\n",
    "    df = df[df[\"year\"].between(2020, 2025, inclusive=\"both\")]\n",
    "\n",
    "    df[\"incident_number\"] = df.get(\"incident_number\", df.get(\"INCIDENT_NUMBER\"))\n",
    "    df[\"incident_number\"] = df[\"incident_number\"].astype(str).str.strip()\n",
    "\n",
    "    df[\"district\"] = df.get(\"district\", df.get(\"DISTRICT\")).fillna(\"UNK\").astype(str).str.upper()\n",
    "    df[\"reporting_area\"] = (\n",
    "        df.get(\"reporting_area\", df.get(\"REPORTING_AREA\"))\n",
    "        .astype(str)\n",
    "        .str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "        .str.zfill(3)\n",
    "    )\n",
    "\n",
    "    df[\"latitude\"] = pd.to_numeric(df.get(\"latitude\"), errors=\"coerce\")\n",
    "    df[\"longitude\"] = pd.to_numeric(df.get(\"longitude\"), errors=\"coerce\")\n",
    "    inside_bounds = (\n",
    "        df[\"latitude\"].between(BOSTON_BOUNDS[\"lat_min\"], BOSTON_BOUNDS[\"lat_max\"], inclusive=\"both\")\n",
    "        & df[\"longitude\"].between(BOSTON_BOUNDS[\"lon_min\"], BOSTON_BOUNDS[\"lon_max\"], inclusive=\"both\")\n",
    "    )\n",
    "    coord_missing = df[\"latitude\"].isna() & df[\"longitude\"].isna()\n",
    "    df = df[inside_bounds | coord_missing]\n",
    "\n",
    "    df[\"shooting\"] = df.get(\"shooting\", df.get(\"SHOOTING\"))\n",
    "    df[\"is_shooting\"] = df[\"shooting\"].astype(str).str.upper().isin([\"Y\", \"YES\", \"TRUE\", \"1\"])\n",
    "\n",
    "    df[\"incident_daypart\"] = df[\"hour\"].apply(make_daypart)\n",
    "    df[\"weekday\"] = df[\"occurred_on_dt\"].dt.day_name()\n",
    "\n",
    "    df[\"offense_code_group\"] = df.get(\"offense_code_group\", df.get(\"OFFENSE_CODE_GROUP\"))\n",
    "    df[\"offense_description\"] = df.get(\"offense_description\", df.get(\"OFFENSE_DESCRIPTION\"))\n",
    "\n",
    "    df = df.sort_values(\"occurred_on_dt\").drop_duplicates(subset=[\"incident_number\"], keep=\"last\")\n",
    "\n",
    "    keep_cols = [\n",
    "        \"incident_number\",\n",
    "        \"offense_code\",\n",
    "        \"offense_code_group\",\n",
    "        \"offense_description\",\n",
    "        \"district\",\n",
    "        \"reporting_area\",\n",
    "        \"is_shooting\",\n",
    "        \"occurred_on_dt\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"hour\",\n",
    "        \"incident_daypart\",\n",
    "        \"weekday\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"street\",\n",
    "        \"ucr_part\",\n",
    "    ]\n",
    "    missing_keep = [col for col in keep_cols if col not in df.columns]\n",
    "    if missing_keep:\n",
    "        diagnostics[\"missing_columns\"] = missing_keep\n",
    "\n",
    "    crime_clean = df.reindex(columns=keep_cols)\n",
    "    return crime_clean, diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace15ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime_clean shape: (214626, 17)\n",
      "Saved crime outputs:\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_incidents_clean.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_incidents_clean.parquet\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_by_district_month.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_by_reporting_area_month.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_by_year.csv\n",
      "Crime diagnostics: {'source': 'CrimeData.csv', 'rows': 214628}\n"
     ]
    }
   ],
   "source": [
    "crime_clean, crime_diag = clean_crime_data(CRIME_FILE)\n",
    "print(\"crime_clean shape:\", crime_clean.shape)\n",
    "crime_outputs = []\n",
    "if crime_clean.empty:\n",
    "    print(\"No crime data available; skipping crime exports.\")\n",
    "else:\n",
    "    crime_clean_path_csv = OUT_DIR / \"crime_incidents_clean.csv\"\n",
    "    crime_clean_path_parquet = OUT_DIR / \"crime_incidents_clean.parquet\"\n",
    "    crime_clean.to_csv(crime_clean_path_csv, index=False)\n",
    "    crime_outputs.append(crime_clean_path_csv)\n",
    "\n",
    "    if safe_to_parquet(crime_clean, crime_clean_path_parquet):\n",
    "        crime_outputs.append(crime_clean_path_parquet)\n",
    "\n",
    "    crime_by_district_month = (\n",
    "        crime_clean.groupby([\"district\", \"year\", \"month\"], as_index=False)\n",
    "        .agg(\n",
    "            incident_count=(\"incident_number\", \"count\"),\n",
    "            shooting_incidents=(\"is_shooting\", \"sum\"),\n",
    "            predominant_offense=(\"offense_code_group\", top_mode),\n",
    "        )\n",
    "        .sort_values([\"year\", \"month\", \"district\"])\n",
    "    )\n",
    "    crime_by_district_month_path = OUT_DIR / \"crime_by_district_month.csv\"\n",
    "    crime_by_district_month.to_csv(crime_by_district_month_path, index=False)\n",
    "    crime_outputs.append(crime_by_district_month_path)\n",
    "\n",
    "    crime_by_reporting_area = (\n",
    "        crime_clean.groupby([\"reporting_area\", \"year\", \"month\"], as_index=False)\n",
    "        .agg(\n",
    "            incident_count=(\"incident_number\", \"count\"),\n",
    "            shooting_incidents=(\"is_shooting\", \"sum\"),\n",
    "            predominant_offense=(\"offense_code_group\", top_mode),\n",
    "        )\n",
    "        .sort_values([\"year\", \"month\", \"reporting_area\"])\n",
    "    )\n",
    "    crime_by_reporting_area_path = OUT_DIR / \"crime_by_reporting_area_month.csv\"\n",
    "    crime_by_reporting_area.to_csv(crime_by_reporting_area_path, index=False)\n",
    "    crime_outputs.append(crime_by_reporting_area_path)\n",
    "\n",
    "    crime_by_year = (\n",
    "        crime_clean.groupby(\"year\", as_index=False)\n",
    "        .agg(\n",
    "            incident_count=(\"incident_number\", \"count\"),\n",
    "            shooting_incidents=(\"is_shooting\", \"sum\"),\n",
    "        )\n",
    "        .sort_values(\"year\")\n",
    "    )\n",
    "    crime_by_year_path = OUT_DIR / \"crime_by_year.csv\"\n",
    "    crime_by_year.to_csv(crime_by_year_path, index=False)\n",
    "    crime_outputs.append(crime_by_year_path)\n",
    "\n",
    "    print(\"Saved crime outputs:\")\n",
    "    for path in crime_outputs:\n",
    "        print(\" -\", path)\n",
    "\n",
    "print(\"Crime diagnostics:\", crime_diag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2844c733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent crime incidents:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_number</th>\n",
       "      <th>district</th>\n",
       "      <th>occurred_on_dt</th>\n",
       "      <th>incident_daypart</th>\n",
       "      <th>offense_code_group</th>\n",
       "      <th>is_shooting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14099</th>\n",
       "      <td>252078778</td>\n",
       "      <td>E18</td>\n",
       "      <td>2025-09-20 04:25:00+00:00</td>\n",
       "      <td>overnight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85812</th>\n",
       "      <td>252078772</td>\n",
       "      <td>D4</td>\n",
       "      <td>2025-09-20 02:52:00+00:00</td>\n",
       "      <td>overnight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85865</th>\n",
       "      <td>252078763</td>\n",
       "      <td>D4</td>\n",
       "      <td>2025-09-20 02:38:00+00:00</td>\n",
       "      <td>overnight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85848</th>\n",
       "      <td>252078755</td>\n",
       "      <td>B3</td>\n",
       "      <td>2025-09-20 02:08:00+00:00</td>\n",
       "      <td>overnight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78868</th>\n",
       "      <td>252078754</td>\n",
       "      <td>D4</td>\n",
       "      <td>2025-09-20 02:08:00+00:00</td>\n",
       "      <td>overnight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      incident_number district            occurred_on_dt incident_daypart  offense_code_group  is_shooting\n",
       "14099       252078778      E18 2025-09-20 04:25:00+00:00        overnight                 NaN        False\n",
       "85812       252078772       D4 2025-09-20 02:52:00+00:00        overnight                 NaN        False\n",
       "85865       252078763       D4 2025-09-20 02:38:00+00:00        overnight                 NaN        False\n",
       "85848       252078755       B3 2025-09-20 02:08:00+00:00        overnight                 NaN        False\n",
       "78868       252078754       D4 2025-09-20 02:08:00+00:00        overnight                 NaN        False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly incident counts (last 12 months if available):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>incident_count</th>\n",
       "      <th>shooting_incidents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2024</th>\n",
       "      <th>10</th>\n",
       "      <td>6826</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6523</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6761</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">2025</th>\n",
       "      <th>1</th>\n",
       "      <td>6206</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5619</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6704</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6424</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7142</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6702</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7089</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7263</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4429</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            incident_count  shooting_incidents\n",
       "year month                                    \n",
       "2024 10               6826                  37\n",
       "     11               6523                  42\n",
       "     12               6761                  32\n",
       "2025 1                6206                  32\n",
       "     2                5619                  31\n",
       "     3                6704                  42\n",
       "     4                6424                  51\n",
       "     5                7142                  45\n",
       "     6                6702                  53\n",
       "     7                7089                  60\n",
       "     8                7263                  59\n",
       "     9                4429                  29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if not crime_clean.empty:\n",
    "    preview_cols = [\n",
    "        \"incident_number\",\n",
    "        \"district\",\n",
    "        \"occurred_on_dt\",\n",
    "        \"incident_daypart\",\n",
    "        \"offense_code_group\",\n",
    "        \"is_shooting\",\n",
    "    ]\n",
    "    preview = crime_clean[preview_cols].sort_values(\"occurred_on_dt\", ascending=False).head(5)\n",
    "    print(\"Recent crime incidents:\")\n",
    "    display(preview)\n",
    "\n",
    "    print(\"Monthly incident counts (last 12 months if available):\")\n",
    "    recent_months = (\n",
    "        crime_clean.sort_values(\"occurred_on_dt\")\n",
    "        .groupby([\"year\", \"month\"])\n",
    "        .agg(\n",
    "            incident_count=(\"incident_number\", \"count\"),\n",
    "            shooting_incidents=(\"is_shooting\", \"sum\"),\n",
    "        )\n",
    "        .tail(12)\n",
    "    )\n",
    "    display(recent_months)\n",
    "else:\n",
    "    print(\"Crime dataset is empty; nothing to profile.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2acb56",
   "metadata": {},
   "source": [
    "## Output summary\n",
    "Quick reference of files generated by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ad27fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts written to:\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/property_assessments_clean.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/property_assessments_clean.parquet\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/property_by_zip_year.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/property_by_res_type_year.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_incidents_clean.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_incidents_clean.parquet\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_by_district_month.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_by_reporting_area_month.csv\n",
      " - /Users/jeet/github/Boston-Area-Price-and-Crime-Prediction/backend/notebooks/processed/crime_by_year.csv\n"
     ]
    }
   ],
   "source": [
    "all_outputs = []\n",
    "if 'property_outputs' in globals():\n",
    "    all_outputs.extend(property_outputs)\n",
    "if 'crime_outputs' in globals():\n",
    "    all_outputs.extend(crime_outputs)\n",
    "\n",
    "if all_outputs:\n",
    "    print(\"Artifacts written to:\")\n",
    "    for path in all_outputs:\n",
    "        print(\" -\", path)\n",
    "else:\n",
    "    print(\"No artifacts were written (check diagnostics above).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
